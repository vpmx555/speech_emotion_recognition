import os
import glob
import torch
import torchaudio
from torch.utils.data import Dataset
from features import prosody, mfcc, HuBERT
import torch.nn.functional as F

# üîπ Mapping c·∫£m x√∫c t·ª´ ID sang nh√£n
EMOTION_MAP = {
    "01": "neutral",
    "02": "calm",
    "03": "happy",
    "04": "sad",
    "05": "angry",
    "06": "fearful",
    "07": "disgust",
    "08": "surprised"
}


# üîπ 1Ô∏è‚É£ Load file √¢m thanh v√† nh√£n c·∫£m x√∫c
def load_audio_files(folder_path, device="cuda"):
    audio_files_names = glob.glob(os.path.join(folder_path, "*.wav"))
    audio_list = []
    labels = []

    for file in audio_files_names:
        filename = os.path.basename(file)  # Ch·ªâ l·∫•y t√™n file
        emotion_id = filename.split("-")[2]  # L·∫•y Emotion ID
        emotion_label = EMOTION_MAP.get(emotion_id, "unknown")  # Chuy·ªÉn ID th√†nh nh√£n

        waveform, sr = torchaudio.load(file)
        waveform = waveform.mean(dim=0)  # Chuy·ªÉn v·ªÅ mono n·∫øu c·∫ßn
        audio_list.append(waveform.to(device))
        labels.append(emotion_label)

    assert len(audio_list) != 0, "‚ùå Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c load!"
    return audio_files_names, audio_list, labels

# üîπ 2Ô∏è‚É£ Dataset Class ƒë·ªÉ s·ª≠ d·ª•ng DataLoader
class RAVDESSDataset(Dataset):
    def __init__(self, folder_path, device="cuda"):

        self.folder_path = folder_path
        self.audio_files_names, self.audio_list, self.labels = load_audio_files(folder_path, device)
        self.device = device

        self.feature_extractor, self.hubert_model = HuBERT.load_hubert_model(device)

        self.mfcc_features = self.get_list_mfcc_feature()
        self.prosody_features = self.get_list_prosody_feature()
        self.hubert_features = self.get_list_hubert_feature()

        assert len(self.mfcc_features) == len(self.audio_list), "MFCC feature extraction failed!"
        assert len(self.prosody_features) == len(self.audio_list), "Prosody feature extraction failed!"
        assert len(self.hubert_features) == len(self.audio_list), "HuBERT feature extraction failed!"

    def __len__(self):
        return len(self.audio_list)

    def __getitem__(self, idx):
        mfcc = self.mfcc_features[idx]
        prosody = self.prosody_features[idx]
        hubert = self.hubert_features[idx]

        # Chuy·ªÉn nh√£n t·ª´ string sang s·ªë (0-7)
        label_index = list(EMOTION_MAP.values()).index(self.labels[idx])
        label_one_hot = F.one_hot(torch.tensor(label_index, dtype=torch.long), num_classes=8).float()

        return mfcc, prosody, hubert, label_one_hot

    def get_list_mfcc_feature(self):
        """Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng MFCC cho to√†n b·ªô dataset."""
        return [mfcc.extract_mfcc(audio, 16000, 13, self.device) for audio in self.audio_list]

    def get_list_prosody_feature(self):
        """Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng Prosody cho to√†n b·ªô dataset."""
        full_audio_paths = [os.path.join(self.folder_path, filename) for filename in self.audio_files_names]

        prosody_list = prosody.extract_prosody_batch(full_audio_paths, self.device)  # (num_samples, 103)
        for i in range(len(prosody_list)):
            if torch.isnan(prosody_list[i]).any():
                prosody_list[i] = torch.nan_to_num(prosody_list[i], nan=0.0)
        return prosody_list

    def get_list_hubert_feature(self):
        """Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HuBERT cho to√†n b·ªô dataset."""
        return [HuBERT.extract_hubert_features(audio, 16000, self.feature_extractor, self.hubert_model, self.device)
                for audio in self.audio_list]